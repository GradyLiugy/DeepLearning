{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import datasets,layers,models\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def load_image(img_path,size = (32,32)):\n",
    "    label = tf.constant(1,tf.int8) if tf.strings.regex_full_match(img_path,\".*automobile.*\") \\\n",
    "            else tf.constant(0,tf.int8)\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n",
    "    img = tf.image.resize(img,size)/255.0\n",
    "    return(img,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用并行化预处理num_parallel_calls 和预存数据prefetch来提升性能\n",
    "ds_train = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\") \\\n",
    "           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "           .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "           .prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "ds_test = tf.data.Dataset.list_files(\"./data/cifar2/test/*/*.jpg\") \\\n",
    "           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "           .batch(BATCH_SIZE) \\\n",
    "           .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#查看部分样本\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(8,8)) \n",
    "for i,(img,label) in enumerate(ds_train.unbatch().take(9)):\n",
    "    ax=plt.subplot(3,3,i+1)\n",
    "    ax.imshow(img.numpy())\n",
    "    ax.set_title(\"label = %d\"%label)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([]) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in ds_train.take(1):\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session() #清空会话\n",
    "\n",
    "inputs = layers.Input(shape=(32,32,3))\n",
    "x = layers.Conv2D(32,kernel_size=(3,3))(inputs)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(64,kernel_size=(5,5))(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Dropout(rate=0.1)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32,activation='relu')(x)\n",
    "outputs = layers.Dense(1,activation = 'sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs = inputs,outputs = outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join('data', 'autograph', stamp)\n",
    "\n",
    "## 在 Python3 下建议使用 pathlib 修正各操作系统的路径\n",
    "# from pathlib import Path\n",
    "# stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# logdir = str(Path('./data/autograph/' + stamp))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "history = model.fit(ds_train,epochs= 10,validation_data=ds_test,\n",
    "                    callbacks = [tensorboard_callback],workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir ./data/keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在tensorboard中查看模型\n",
    "notebook.start(\"--logdir ./data/keras_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dfhistory = pd.DataFrame(history.history)\n",
    "dfhistory.index = range(1,len(dfhistory) + 1)\n",
    "dfhistory.index.name = 'epoch'\n",
    "\n",
    "dfhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history,\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history,\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "可以使用evaluate对数据进行评估\n",
    "val_loss,val_accuracy = model.evaluate(ds_test,workers=4)\n",
    "print(val_loss,val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in ds_test.take(1):\n",
    "    print(model.predict_on_batch(x[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存权重，该方式仅仅保存权重张量\n",
    "model.save_weights('./data/tf_model_weights.ckpt',save_format = \"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署\n",
    "\n",
    "model.save('./data/tf_model_savedmodel', save_format=\"tf\")\n",
    "print('export saved model.')\n",
    "\n",
    "model_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\n",
    "model_loaded.evaluate(ds_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}